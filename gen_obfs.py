"""
This script generates obfuscated data for the other scripts.
The obfuscated data is generated by applying the obfuscation function to the original data.
The obfuscation function is defined in the utils.obfs module.
The obfuscated data is then saved to a file.
Arguments control if packet padding or packet delay or both is added.

"""
from argparse import ArgumentParser
from utils.obfs import *
from utils.data import *


def parse_args():
    parser = ArgumentParser(
                        )
    parser.add_argument('--data',
                        type = str,
                        help = "Path to dataset pickle file.",
                        required = True)
    parser.add_argument('--outfile',
                        type=str,
                        help = 'Output file for results.',
                        required=True)
    parser.add_argument('--padding',
                        action='store_true',
                        help='Apply padding obfuscation.')
    parser.add_argument('--delay',
                        action='store_true',
                        help='Apply delay obfuscation.')
    parser.add_argument('--overhead',
                        type=float,
                        default=0.5,
                        help='Target overhead for padding obfuscation.')
    return parser.parse_args()


if __name__ == "__main__":
    """
    """
    args = parse_args()
    # load dataset
    #pklpath = '../data/ssh/processed_nov17_fixtime.pkl'
    pklpath = args.data
    chains = load_dataset(pklpath)
    # chains is a nested array of N hops (list) each with 1-2 samples
    
    # create list of all sizes for histogram
    all_incoming_packet_sizes = []
    all_outgoing_packet_sizes = []
    for chain in chains:    
        for sample in chain:
            incoming_sizes = sample[1][sample[2] < 0]
            outgoing_sizes = sample[1][sample[2] > 0]
            all_incoming_packet_sizes.extend(incoming_sizes)
            all_outgoing_packet_sizes.extend(incoming_sizes)
    incoming_histo = NumpyHisto(all_incoming_packet_sizes)
    outgoing_histo = NumpyHisto(all_outgoing_packet_sizes)
    
    gen_count = 10
    
    if args.delay:
        # apply delay obfuscation
        print("Applying delay obfuscation...")
        for chain in chains:
            for i in range(len(chain)):
                sample = chain[i]
                obfs_samples = []
                for i in range(gen_count):
                    times, sizes, directions = sample[0], sample[1], sample[2]
                    sizes, times, directions = delay_and_sort_traffic_packets(sizes, times, directions, 
                                                    max_delay=1.0, delay_probability=0.2)
                    obfs_samples.append(np.array([times.numpy(), sizes.numpy(), directions.numpy()]))
                chain[i] = obfs_samples
    
    if args.padding:
        # apply padding obfuscation
        print("Applying padding obfuscation...")
        for chain in chains:
            for i in range(len(chain)):
                sample = chain[i]
                obfs_samples = []
                for i in range(gen_count):
                    times, sizes, directions = sample[0], sample[1], sample[2]
                    sizes, times, directions = insert_dummy_packets_torch_exponential(sizes, times, directions, 
                                                    num_dummy_packets = args.overheads * len(directions) * 2, 
                                                    total_duration = times[-1],
                                                    size_distributions = [outgoing_histo, incoming_histo])
                    obfs_samples.append(np.array([times.numpy(), sizes.numpy(), directions.numpy()]))
                chain[i] = obfs_samples
                
    with open(args.outfile, 'wb') as f:
        pickle.dump({'obfs': True, 'data': chains}, f)
    print(f"Obfuscated data saved to {args.outfile}")
    